0) Инварианты “рабочей лошадки”
0.1. Локальная работа без облака: всё мгновенно и офлайн.
0.2. Пережить переустановку: только через внешний артефакт (папка пользователя) + Restore.
0.3. MV3: service worker краткоживущий → всё тяжёлое (бэкап/индексация/экспорт) делаем задачами с чекпоинтами и возобновлением.
0.4. Write-path быстрый: запись заметки/перемещение/удаление не ждёт поиска, бэкапа и экспорта.

1) Компоненты и контексты исполнения
1.1. Content Scripts (на любых страницах + вкладках LLM)
    • Триггеры: “Save”, drag selected text, контекстное меню.
    • Собирают clip: {text, selection, pageUrl, title, model?, runId?}.
    • Отправляют в BG: NOTES_CMD_*.
1.2. Sidebar UI (инжект)
    • Рендер: Tabs bar + дерево + editor + поиск + action row.
    • Вся логика состояния UI “тонкая”: читает/пишет через BG API.
    • Внутри: виртуализация дерева (обязательно).
1.3. Comparator UI (ваша главная страница расширения)
    • Использует тот же Notes API:
        ◦ Save Prompt / Save Response / Save Session.
        ◦ Note → Prompt (Replace/Append).
1.4. Background (MV3 Service Worker) = Notes Service
    • Единая точка атомарных транзакций в IndexedDB.
    • Держит только:
        ◦ revision(tabId) счётчики,
        ◦ очередь taskQueue (бэкап/индексация),
        ◦ health-статусы.
1.5. Task Runner (offscreen document или extension page)
    • Выполняет тяжёлые задачи:
        ◦ упаковка снапшотов/сегментов,
        ◦ (опционально) компрессия/шифрование,
        ◦ поиск/индексация.
    • Пишет прогресс и чекпоинты в IDB, чтобы продолжать после kill.
1.6. Settings/Backup Page (extension page)
    • Единственное место, где пользователь:
        ◦ выбирает папку (File System Access),
        ◦ запускает Restore,
        ◦ видит health и статусы.
    • Там же показываем “как дать постоянные права” и предупреждения.

2) Данные и хранилище (IndexedDB)
2.1. Stores (минимум, но правильно)
tabs
    • tabId, name, createdAt, updatedAt, uiPrefs
nodes (карточки, лёгкие)
    • id (uuid), tabId
    • parentId (null=root)
    • orderKey (строка сортировки)
    • createdAt, updatedAt, deletedAt?
    • kind: prompt | response | session | clip | custom | conflict
    • title, preview
    • source: {origin, pageUrl?, chatUrl?, model?, runId?, ts?}
    • tags[], flags
contentChunks
    • key: (noteId, idx) → data (строка/Uint8Array)
    • chunk size: 64KB (v1)
oplog (WAL, append-only)
    • opId, ts, seq, deviceId
    • type, payload
    • state: pendingIndex, pendingBackup, indexed, backedUp
searchIndex_v1 (асинхронный индекс токенов)
    • key: (token, noteId) или (token) -> packed noteIds
    • плюс noteTokens для быстрого “удалить старые токены заметки” при обновлении
tasks
    • taskId, type, state, checkpoint, progress, lastError
backupState
    • folderHandleMeta (не сам handle), lastBackupAt, lastSnapshotId, lastSegSeq, health flags
2.2. Индексы IDB (критично)
    • nodes: индекс (tabId, parentId, orderKey) — это ваш “childrenIndex must-have” без O(N).
    • nodes: индекс (tabId, createdAt) для группировки по датам/фильтров.
    • nodes: индекс (tabId, kind) для быстрых views.
    • oplog: индекс (state, seq) для обработки задач.

3) Порядок и DnD: orderKey “по-взрослому”
3.1. Выбор подхода
    • LexoRank/fractional indexing строками (base-62/base-64 алфавит + midpoint).
    • Не используем числовые индексы 1,2,3 (иначе массовые UPDATE).
3.2. Операции
    • Вставка между leftKey и rightKey → генерим midKey.
    • Вставка в начало/конец → before(firstKey) / after(lastKey).
3.3. Массовый DnD (100 нод)
    • Нельзя генерить 100 раз “mid между соседями” цепочкой — уплотнит.
    • Делается range allocation:
        ◦ берём окно [L, R] (ключи соседей до/после вставки),
        ◦ генерим N равномерных ключей в этом диапазоне детерминированно,
        ◦ пишем батчем в одной транзакции.
3.4. Ребаланс (редкий, локальный)
    • Если ключи “слиплись” (длина растёт/нельзя вставить) → rebalance только детей одного parentId:
        ◦ пересоздаём orderKey всем детям (O(k)),
        ◦ делаем как отдельную BG-команду/транзакцию, UI показывает короткий “Reordering…”.

4) Командный API (всё атомарно через BG)
4.1. Команды (примерный контракт)
    • TAB_CREATE/RENAME/SWITCH/CLOSE
    • NOTE_CREATE_ROOT(tabId, text, meta)
    • NOTE_CREATE_CHILD(parentId, text, meta)
    • NOTE_UPDATE_TEXT(noteId, newText)
    • NOTE_MOVE(noteId, newParentId, positionHint) (BG сам считает orderKey)
    • NOTE_DELETE_TOPMOST(noteIds[])
    • NOTE_TOGGLE_PIN/ARCHIVE/TAG
    • EXPORT_SELECTED(noteIds[], format)
    • RESTORE_FROM_FOLDER(manifestRef, mode)
    • BACKUP_NOW()
4.2. События
    • REVISION_BUMP(tabId, rev) (UI инвалидация кешей)
    • TASK_PROGRESS(taskId, pct, stage)
    • BACKUP_HEALTH(status, warnings[])
    • INDEX_STATUS(lagSeconds, pendingCount)
4.3. Атомарность
Каждая пользовательская команда в BG:
    1. пишет изменения в nodes/contentChunks,
    2. добавляет запись в oplog,
    3. bump revision,
всё в одной транзакции IDB.

5) UI/Perf: дерево, мультиселект, группы дат
5.1. Дерево
    • UI получает детей через запрос (tabId,parentId,orderKey) постранично.
    • В UI — кеш childrenByParent + инвалидация по REVISION_BUMP.
    • Виртуализация по “видимым строкам” (flattened view + expanded set).
5.2. Группировка по датам
    • Это view-слой, не структура.
    • Заголовки Today/Yesterday/… вычисляются по createdAt.
    • DnD меняет parent/order, но не “дату”.
5.3. Multi-select
    • Ctrl/Shift/long-press.
    • Удаление — BG режет выбор до top-most (без двойных удалений дочерних).

6) Поиск: быстрый UI + фоновая индексация (учёт review)
6.1. Что ищем в v1
    • Мгновенно: title/preview/tags/kind/model/date.
    • Быстро по телу: через асинхронный token-index, без блокировки write-path.
6.2. Индексатор
    • Триггер: новые ops в oplog с state=pendingIndex.
    • Task Runner берёт батч ops → пересчитывает токены для затронутых noteId → обновляет searchIndex_v1 и noteTokens.
    • Допуск: новая заметка появляется в поиске через 0.5–2 сек.
    • UI показывает маленький индикатор “Indexing…” если lag заметный.
6.3. Токены (простая схема v1)
    • нормализация: lower + split по не-буквенно-цифровым + фильтр длины.
    • источники токенов:
        ◦ title, tags, preview,
        ◦ первые N KB тела (например 32–64KB) как компромисс.
    • Полный “FTS” можно добавить позже, не ломая контракт.

7) Backup “по умолчанию” в папку пользователя (без облака)
7.1. UX-позиция (важно)
    • Автобэкап включён по умолчанию, но активируется только после настройки папки.
    • Settings page:
        ◦ “Выберите папку для бэкапов”
        ◦ после выбора: показать “права: granted / prompt / denied”
        ◦ рекомендовать режим “постоянный доступ”, иначе будет деградация.
7.2. Health-check (обязательно)
    • При старте Settings, раз в сутки, и перед backup:
        ◦ проверить permission,
        ◦ проверить доступность папки,
        ◦ пробная запись/чтение .sidebar_health.
    • Если broken → статус красный + “Re-link folder”.
7.3. Формат хранения в папке
/SidebarNotes/
  manifest.json
  snapshots/
    snapshot_<unix>.bin
  segments/
    oplog_<from>-<to>.bin
  blobs/ (опционально v1, если выносите большие чанки отдельно)
  logs/ (опционально)
7.4. manifest.json (v1)
    • schemaVersion
    • deviceId
    • createdAt, appVersion, archiveVersion
    • lastSnapshot
    • segments[]: {fromSeq,toSeq,file,hash}
    • encryption: {enabled,kdf,salt,kdfParams} (по умолчанию можно выключить в v1, но предусмотреть поля)
    • stats: {notesCount, totalBytes}
7.5. Стратегия: snapshot + segments
    • Snapshot: периодически (например раз в день или каждые N сегментов).
    • Segments: инкременты по WAL (например 1–10MB или 1–5k ops).
    • Всё chunked/resumable:
        ◦ task checkpoint хранит “на каком seq остановились”.
7.6. Планировщик
    • chrome.alarms + “при idle” + “после серии ops”.
    • Если нет прав — не спамить, а ставить статус “Backup pending user action”.

8) Restore после переустановки (главный кейс)
8.1. Пользователь открывает Settings → выбирает папку → “Restore”.
8.2. Процесс:
    1. прочитать manifest.json
    2. применить lastSnapshot → восстановить tabs/nodes/content
    3. последовательно применить сегменты oplog до конца
    4. поднять revision и построить индекс асинхронно
8.3. Режимы restore
    • wipe-and-restore (чисто восстановить из папки)
    • merge (если в новом профиле уже есть данные):
        ◦ при конфликте текста/структуры — создаём conflict copy (см. ниже)

9) Конфликты (из review: UX обязателен)
9.1. Когда возможны
    • Merge-restore поверх существующих данных.
    • Импорт “второго бэкапа” в тот же стор.
9.2. Поведение v1: “Conflict copy”, но управляемо
    • Создаём note kind=conflict рядом (тот же parentId) с:
        ◦ title: ⚠ Conflict: <title>
        ◦ source: {conflictWith: noteId, incomingFrom: deviceId, ts}
    • В дереве: маркер ⚠ + фильтр “Conflicts”.
    • В editor при открытии конфликта:
        ◦ вкладки/панели: “Original” / “Incoming”
        ◦ кнопки:
            ▪ Keep original (удалить conflict)
            ▪ Replace with incoming (перезаписать оригинал, удалить conflict)
            ▪ Merge manually (открыть incoming в editor, пользователь правит, потом Resolve)

10) Migration с v57 localStorage → IDB (обязательный путь)
10.1. Триггер
    • On install/update: если найден legacy state (localStorage на extension origin / известный ключ).
10.2. План миграции
    1. создать tabId="Legacy" (или несколько, если были tabs)
    2. обойти legacy дерево:
        ◦ создать nodes с parentId/orderKey по исходному порядку
        ◦ тело → contentChunks (64KB)
    3. записать migrationState {from:"v57", done:true, ts}
    4. индекс/бэкап задачи запускаются после миграции
10.3. Безопасность
    • Старый localStorage не удаляем автоматически; предлагаем кнопку “Cleanup legacy”.

11) Задачи и устойчивость (чтобы MV3 не ломал фон)
11.1. Любая тяжёлая операция = task с checkpoint
    • backup segment pack
    • snapshot build
    • index batch
    • export large
11.2. Возобновление
    • task state в tasks store
    • при запуске SW/Settings UI — продолжить незавершённое

12) MVP v1 (фиксированный скоуп)
12.1. Дерево+DnD+multiselect+экспорт HTML/MD/JSON.
12.2. Save Prompt/Response/Session + Note→Prompt.
12.3. IDB: nodes + contentChunks (64KB) + WAL.
12.4. Поиск: быстрый по мета + фоновый токен-индекс (eventual).
12.5. Backup default: Local Folder (авто при наличии прав) + Restore после reinstall.
12.6. Migration с v57.


==========================
1) WAL / OpLog: требования
1.1. Идемпотентность: повторное применение одного и того же op не меняет результат.
1.2. Детерминизм: одинаковый набор ops → одинаковое состояние.
1.3. Проверка конфликтов: для операций, меняющих note, нужен лёгкий механизм “ожидаемая ревизия”.
1.4. Инкрементальность: ops режутся в сегменты, применяются потоково, с чекпоинтами.

2) Глобальные идентификаторы и ревизии
2.1. Идентификаторы
    • deviceId: UUID, генерится при первом запуске (хранится локально и попадает в бэкапы).
    • opId: UUID v4.
    • seq: монотонный счётчик на устройстве (uint64), увеличивается на 1 на каждую операцию.
2.2. Ревизия сущностей (для конфликтов)
У каждой note храним:
    • rev (uint32), старт = 1 при create.
    • Любая мутация note = rev+1.
Опции:
    • v1: только rev (достаточно для merge/import).
    • v1.5: добавить updatedAt как доп. эвристику, но не как источник истины.

3) Формат записи op (канонический)
{
  "opId": "uuid",
  "deviceId": "uuid",
  "seq": 12345,
  "ts": 1735152000123,
  "type": "NOTE_UPDATE_TEXT",
  "payload": { }
}
Обязательные поля:
    • opId, deviceId, seq, ts, type, payload
Инварианты:
    • seq строго растёт в пределах deviceId.
    • Применение ops одного deviceId всегда по возрастанию seq.

4) Типы операций и payload
4.1. Tabs
TAB_CREATE
{ "tabId":"uuid", "name":"Home", "createdAt": 1735 }
TAB_RENAME
{ "tabId":"uuid", "name":"New name" }
TAB_CLOSE (если нужно)
{ "tabId":"uuid", "closedAt": 1735 }

4.2. Notes: создание/текст/структура
NOTE_CREATE
{
  "note": {
    "id":"uuid",
    "tabId":"uuid",
    "parentId": null,
    "orderKey":"0|i",
    "kind":"prompt",
    "title":"…",
    "preview":"…",
    "source": { "origin":"comparator", "runId":"...", "model":null, "pageUrl":"..." },
    "tags": [],
    "flags": {},
    "createdAt": 1735,
    "updatedAt": 1735,
    "rev": 1
  },
  "content": {
    "format":"plain",
    "chunks": [
      { "idx":0, "data":"..." }
    ],
    "chunkSize": 65536
  }
}
NOTE_UPDATE_TEXT (полная замена, v1)
{
  "noteId":"uuid",
  "prevRev": 7,
  "nextRev": 8,
  "content": {
    "format":"plain",
    "chunks":[ {"idx":0,"data":"..."}, {"idx":1,"data":"..."} ],
    "chunkSize": 65536
  },
  "title":"optional updated title",
  "preview":"optional updated preview",
  "updatedAt": 1735
}
NOTE_PATCH_TEXT (v1.5+, если захотите)
{
  "noteId":"uuid",
  "prevRev": 7,
  "nextRev": 8,
  "patch": { "algo":"diff-match-patch", "data":"..." },
  "updatedAt": 1735
}
NOTE_MOVE
{
  "noteId":"uuid",
  "prevRev": 3,
  "nextRev": 4,
  "from": { "parentId":"uuid|null", "orderKey":"..." },
  "to":   { "parentId":"uuid|null", "orderKey":"..." },
  "updatedAt": 1735
}
NOTE_REORDER_BULK (массовый DnD / rebalance для одного parent)
{
  "parentId":"uuid|null",
  "items":[
    {"noteId":"uuid1","prevRev":10,"nextRev":11,"orderKey":"..."},
    {"noteId":"uuid2","prevRev":2,"nextRev":3,"orderKey":"..."}
  ],
  "updatedAt": 1735
}
NOTE_DELETE (soft delete)
{
  "noteId":"uuid",
  "prevRev": 12,
  "nextRev": 13,
  "deletedAt": 1735
}
NOTE_RESTORE (из корзины / undo)
{
  "noteId":"uuid",
  "prevRev": 13,
  "nextRev": 14,
  "restore": { "parentId":"uuid|null", "orderKey":"..." },
  "updatedAt": 1735
}

4.3. Метаданные
NOTE_SET_TAGS
{ "noteId":"uuid", "prevRev":5, "nextRev":6, "tags":["a","b"], "updatedAt": 1735 }
NOTE_SET_FLAGS
{ "noteId":"uuid", "prevRev":5, "nextRev":6, "flags":{"pinned":true}, "updatedAt": 1735 }

4.4. Конфликты (не “op”, а результат применения)
Отдельного op типа “CONFLICT” можно не делать. Конфликт фиксируется как:
    • создание note kind=conflict обычным NOTE_CREATE (с source.conflictWith).

5) Правила применения ops (apply engine)
5.1. Дедуп / порядок
    • Для каждого deviceId хранить lastAppliedSeq.
    • При apply: если seq <= lastAppliedSeq → пропустить.
    • Иначе применить и выставить lastAppliedSeq = seq.
5.2. Проверка ревизий
Для ops с prevRev/nextRev:
    • Если note отсутствует:
        ◦ если op = CREATE → ок
        ◦ иначе → пропустить или в “import warnings” (v1 достаточно пропустить).
    • Если note.rev != prevRev → конфликт:
        ◦ создаём conflict-note (см. UX), оригинал не трогаем.
    • Если совпало → применяем, ставим rev = nextRev.
5.3. Атомарность
    • Применение одного op = одна транзакция IDB:
        ◦ обновить nodes/contentChunks,
        ◦ обновить индексы/кеши минимально,
        ◦ записать служебное applyState.

6) Сегменты WAL на диске (Local Folder)
6.1. Имена файлов
    • segments/oplog_<deviceId>_<fromSeq>-<toSeq>.bin
6.2. Содержимое (v1 просто и надёжно)
    • JSONL (по строке на op) + gzip.
    • Рядом: hash в manifest (sha256 от gzip-байт).
(Бинарный CBOR/msgpack можно позже, но JSONL проще отлаживать и восстанавливать.)

7) Snapshot формат
7.1. Имя
    • snapshots/snapshot_<deviceId>_<unix>.bin
7.2. Состав (v1)
    • tabs[]
    • nodes[] (включая rev)
    • contentChunks как пачки {noteId, idx, data} (gzip)
    • applyState (lastAppliedSeq per deviceId), чтобы после restore не переигрывать дубли.
Практика: делать snapshot реже, чтобы не плодить гигабайты; инкременты — сегментами.

8) Manifest (в папке)
{
  "schemaVersion": 2,
  "archiveVersion": 1,
  "deviceId": "uuid",
  "createdAt": 1735152000,
  "lastSnapshot": "snapshots/snapshot_uuid_1703500800.bin",
  "segments": [
    { "deviceId":"uuid", "from": 0, "to": 1000, "file": "segments/oplog_uuid_0-1000.bin", "hash":"sha256:..." }
  ],
  "encryption": { "enabled": false, "kdf": "argon2id", "salt": "...", "kdfParams": { } }
}

9) Restore / Merge алгоритм
9.1. Wipe-and-restore
    1. очистить IDB
    2. применить snapshot
    3. применить сегменты (по каждому deviceId по возрастанию seq)
    4. запустить задачи: индексация поиска + health
9.2. Merge (поверх существующих)
    • snapshot не “перезаписывает всё”, а импортится:
        ◦ если noteId не существует → create
        ◦ если существует → сравнить rev:
            ▪ если одинаково → ок
            ▪ если различается → создать conflict-note (kind=conflict)
    • затем применить сегменты с ревизионной проверкой (п.5.2)

10) Задачи (Tasks) и чекпоинты (MV3-safe)
10.1. Общая модель
tasks store:
    • taskId, type, status (queued/running/paused/done/failed)
    • createdAt, updatedAt
    • priority (index > backup > export)
    • leaseUntil (для “взятия” задачи)
    • params (небольшие)
    • checkpoint (прогресс + курсоры)
    • attempts, lastError
Task runner:
    • берёт задачу, ставит running + leaseUntil=now+30s
    • делает микрошаг (например 100–500 ops или 1–5MB)
    • сохраняет checkpoint
    • продлевает lease
    • завершает / ставит назад в queue
10.2. Типы задач и чекпоинты
INDEX_BUILD_BATCH
    • params: {tabId?, maxOps:500}
    • checkpoint: {lastOplogSeqProcessed, noteQueueCursor}
    • поведение: обработать pendingIndex ops, обновить searchIndex_v1.
BACKUP_WRITE_SEGMENT
    • params: {folderId, maxBytes:10_000_000}
    • checkpoint: {fromSeq, nextSeq, fileTempName, bytesWritten}
    • поведение: собрать ops [fromSeq..] в файл сегмента, дозаписать, закрыть, обновить manifest.
BACKUP_WRITE_SNAPSHOT
    • params: {folderId}
    • checkpoint: {phase:"tabs|nodes|chunks", cursor, fileTempName}
    • поведение: потоково выгрузить данные в snapshot, затем атомарно rename, обновить manifest.
HEALTH_CHECK_FOLDER
    • params: {folderId}
    • checkpoint: {step:"perm|probeWrite|probeRead"}
    • поведение: обновить BACKUP_HEALTH.
EXPORT_SELECTED
    • params: {noteIds[], format}
    • checkpoint: {cursor, bytesWritten}
    • поведение: собрать top-most, выгрузить HTML/MD/JSON в файл.
10.3. Планирование
    • chrome.alarms:
        ◦ index: каждые 30–60 сек, если есть pendingIndex
        ◦ backup: каждые 10–30 мин, если папка настроена и есть pendingBackup
    • плюс “event-trigger”: после серии ops ставим задачу (debounce).

11) Минимальные гарантии v1
11.1. После любой команды:
    • op записан в oplog
    • состояние применено локально
    • помечено pendingBackup и/или pendingIndex
11.2. При падениях/перезапусках:
    • tasks возобновляются с checkpoint
    • сегменты/снапшоты пишутся через temp-файл + rename (атомарность)
========================================
1) Что индексируем в v1 (чтобы было быстро, но без убийства write-path)
1.1. Поля (источники текста)
Индексатор строит токены из:
    1. title (высший вес)
    2. tags[] (высший вес)
    3. preview (средний вес)
    4. bodyHead = первые 32–64KB текста заметки (низший вес)
Причина: полный body на 50k заметок = дорого. Head даёт “в большинстве случаев нашёл”, остальное можно добивать progressive scan как fallback (не обязателен в v1).
1.2. Нормализация
    • text = text.normalize("NFKC")
    • lowercase (locale-agnostic)
    • опционально: fold accents для ES/FR (á→a) — улучшает UX, цена низкая
    • токены: Unicode-слова [\p{L}\p{N}]+ (буквы/цифры), длина 2..32
    • стоп-слова (минимум): 1–2 буквы, чисто цифровые короткие (например 0..99) выкидываем
1.3. Ограничители (защита от “одна заметка = 200k токенов”)
    • max unique tokens per note: 2 000 (жёсткий кап)
    • max tokens per source:
        ◦ title: 200
        ◦ tags: 200
        ◦ preview: 400
        ◦ bodyHead: 1 200
    • если превышено: берём первые N по порядку появления (детерминированно)

2) Схема индекса в IndexedDB (v1)
2.1. Store A: tokenNotes
Ключ: token + "\u0000" + noteId → 1
Зачем так:
    • лёгкое добавление/удаление отдельных пар,
    • быстрый range-scan по token + "\u0000".
Индексы:
    • primary key (строка)
    • опционально secondary: noteId (если удобно для чистки, но лучше отдельный store ниже)
2.2. Store B: noteTokens
Ключ: noteId → {hash, tokens:[token1, token2, ...]}
Зачем:
    • при обновлении текста надо удалить старые токены без O(N) скана по всему tokenNotes.
hash = быстрый хэш нормализованного индексируемого текста (например, title+tags+preview+bodyHead) чтобы пропускать повторную индексацию.
2.3. Store C (опционально, но полезно): tokenStats
Ключ: token → {df} (document frequency)
Зачем:
    • выбирать “самый редкий токен” первым при поиске (ускоряет пересечения).
Обновление df делаем инкрементально при add/remove токена у заметки.

3) Индексация (eventual), привязка к OpLog
3.1. Какие ops ставят pendingIndex
    • NOTE_CREATE
    • NOTE_UPDATE_TEXT
    • NOTE_SET_TAGS / NOTE_SET_FLAGS (если влияет на title/tags)
    • NOTE_DELETE / NOTE_RESTORE
BG при записи op:
    • помечает oplog.state = pendingIndex
    • bump revision → UI видит изменения сразу, поиск “подъедет” через 0.5–2s.
3.2. Задача INDEX_BUILD_BATCH
Параметры:
    • maxOps (например 200–500 за тик)
    • maxMs (например 50–150ms CPU за тик)
Чекпоинт:
    • {lastSeqProcessed, cursorState}

4) Главное: как удалять старые токены при обновлении (без боли)
4.1. Алгоритм “reindex note”
В транзакции IDB:
    1. Собрать newTokens = tokenize(note.title, tags, preview, bodyHead)
    2. Прочитать old = noteTokens[noteId] (если нет — считать oldTokens = [])
    3. Если old.hash == new.hash → ничего не делать (экономия)
    4. Иначе:
        ◦ toRemove = oldTokens - newTokens
        ◦ toAdd = newTokens - oldTokens
    5. Применить:
        ◦ для каждого t in toRemove: delete tokenNotes[t+"\0"+noteId]
        ◦ для каждого t in toAdd: put tokenNotes[t+"\0"+noteId] = 1
        ◦ обновить noteTokens[noteId] = {hash, tokens:newTokensSorted}
    6. Если есть tokenStats:
        ◦ для toRemove: df-- (удалить запись если df=0)
        ◦ для toAdd: df++
Важно:
    • tokens в noteTokens хранить отсортированными (ускоряет diff двумя указателями, без Set на 2000 элементов).
    • Diff делать как merge-diff (O(n)).
4.2. NOTE_DELETE
    • достать noteTokens[noteId].tokens
    • удалить все tokenNotes[token+"\0"+noteId]
    • удалить noteTokens[noteId]
    • (опц.) обновить df
4.3. Массовые апдейты (например импорт/restore)
    • индексатор работает батчами:
        ◦ сначала пишет nodes/content
        ◦ потом ставит много pendingIndex
        ◦ индексатор проглатывает их порциями, UI показывает “Indexing… (N pending)”.

5) Поиск по индексу: как уложиться в <100ms на больших объёмах
5.1. Парсинг запроса (v1)
    • query → токены тем же tokenizer’ом
    • фильтры отдельно: kind, model, dateRange, tabId
Семантика:
    • по умолчанию AND по токенам
    • пустой запрос → просто дерево/фильтры по метаданным
5.2. План выполнения
    1. Для каждого токена получить кандидатов:
        ◦ range-scan по tokenNotes с префиксом token+"\0"
        ◦ собрать noteId’ы (лимит, например 5k на токен, иначе считаем “очень частотный”)
    2. Начинать с самого редкого токена:
        ◦ если есть tokenStats.df → сортируем по df
        ◦ иначе: берём первый токен и измеряем count (быстро курсором) и переставляем
    3. Пересечение:
        ◦ кандидаты первого токена → Set
        ◦ далее фильтруем по следующим токенам
    4. После пересечения применяем фильтры метаданных (kind/model/date/tabId) через lookup в nodes (батч)
5.3. Ранжирование (простое, но полезное)
score =
    • +3 если токен в title
    • +2 если в tags
    • +1 если в preview
    • +0.5 если в bodyHead
    • +recencyBoost (по updatedAt)
    • +kindBoost (если пользователь фильтрует kind)
Для v1 можно не хранить “позиции”, только источник:
    • при токенизации возвращать map token -> bitmask источников, но хранить это в индексе дорого.
Компромисс v1:
    • ранжировать только по updatedAt + kind + “сколько токенов совпало” (последнее и так известно).

6) Edge-cases (чтобы не было сюрпризов)
6.1. Очень частотные токены (“the”, “and”, “что”, “это”)
    • стоп-лист + лимит postings (если >5k, токен считается “широким” и используется последним).
6.2. Emoji/символы
    • не индексируем.
6.3. CJK (китайский/японский)
    • v1: без сегментации, будет слабее. Если нужно — добавим Intl.Segmenter ветку.
6.4. Смена chunkSize/формата
    • chunking не влияет: индексатор берёт только bodyHead (первые K байт) через чтение первых чанков.

